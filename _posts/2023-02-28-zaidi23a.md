---
title: When Does Re-initialization Work?
abstract: Re-initializing a neural network during training has been observed to improve
  generalization in recent works. Yet it is neither widely adopted in deep learning
  practice nor is it often used in state-of-the-art training protocols. This raises
  the question of when re-initialization works, and whether it should be used together
  with regularization techniques such as data augmentation, weight decay and learning
  rate schedules. In this work, we conduct an extensive empirical comparison of standard
  training with a selection of re-initialization methods to answer this question,
  training over 15,000 models on a variety of image classification benchmarks. We
  first establish that such methods are consistently beneficial for generalization
  in the absence of any other regularization. However, when deployed alongside other
  carefully tuned regularization techniques, re-initialization methods offer little
  to no added benefit for generalization, although optimal generalization performance
  becomes less sensitive to the choice of learning rate and weight decay hyperparameters.
  To investigate the impact of re-initialization methods on noisy data, we also consider
  learning under label noise. Surprisingly, in this case, re-initialization significantly
  improves upon standard training, even in the presence of other carefully tuned regularization
  techniques.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zaidi23a
month: 0
tex_title: When Does Re-initialization Work?
firstpage: 9
lastpage: 24
page: 9-24
order: 9
cycles: false
bibtex_author: Zaidi, Sheheryar and Berariu, Tudor and Kim, Hyunjik and Bornschein,
  Jorg and Clopath, Claudia and Teh, Yee Whye and Pascanu, Razvan
author:
- given: Sheheryar
  family: Zaidi
- given: Tudor
  family: Berariu
- given: Hyunjik
  family: Kim
- given: Jorg
  family: Bornschein
- given: Claudia
  family: Clopath
- given: Yee Whye
  family: Teh
- given: Razvan
  family: Pascanu
date: 2023-02-28
address:
container-title: Proceedings on ``I Can't Believe It's Not Better!  - Understanding
  Deep Learning Through Empirical Falsification'' at NeurIPS 2022 Workshops
volume: '187'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 2
  - 28
pdf: https://proceedings.mlr.press/v187/zaidi23a/zaidi23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
