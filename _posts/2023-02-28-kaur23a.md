---
title: On the Maximum Hessian Eigenvalue and Generalization
abstract: 'The mechanisms by which certain training interventions, such as increasing
  learning rates and applying batch normalization, improve the generalization of deep
  networks remains a mystery. Prior works have speculated that "flatter" solutions
  generalize better than "sharper" solutions to unseen data, motivating several metrics
  for measuring flatness (particularly $\lambda_{\rm max}$ , the largest eigenvalue
  of the Hessian of the loss); and algorithms, such as Sharpness-Aware Minimization
  (SAM), that directly optimize for flatness. Other works question the link between
  $\lambda_{\rm max}$ and generalization. In this paper, we present findings that
  call $\lambda_{\rm max}$’s influence on generalization further into question. We
  show that: (1) while larger learning rates reduce $\lambda_{\rm max}$ for all batch
  sizes, generalization benefits sometimes vanish at larger batch sizes; (2) by scaling
  batch size and learning rate simultaneously, we can change $\lambda_{\rm max}$ without
  affecting generalization; (3) while SAM produces smaller $\lambda_{\rm max}$ for
  all batch sizes, generalization benefits (also) vanish with larger batch sizes;
  (4) for dropout, excessively high dropout probabilities can degrade generalization,
  even as they promote smaller $\lambda_{\rm max}$ ; and (5) while batch-normalization
  does not consistently produce smaller $\lambda_{\rm max}$ , it nevertheless confers
  generalization benefits. While our experiments affirm the generalization benefits
  of large learning rates and SAM for minibatch SGD, the GD-SGD discrepancy demonstrates
  limits to $\lambda_{\rm max}$’s ability to explain generalization in neural networks.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kaur23a
month: 0
tex_title: On the Maximum Hessian Eigenvalue and Generalization
firstpage: 51
lastpage: 65
page: 51-65
order: 51
cycles: false
bibtex_author: Kaur, Simran and Cohen, Jeremy and Lipton, Zachary Chase
author:
- given: Simran
  family: Kaur
- given: Jeremy
  family: Cohen
- given: Zachary Chase
  family: Lipton
date: 2023-02-28
address:
container-title: Proceedings on "I Can't Believe It's Not Better!  - Understanding
  Deep Learning Through Empirical Falsification" at NeurIPS 2022 Workshops
volume: '187'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 2
  - 28
pdf: https://proceedings.mlr.press/v187/kaur23a/kaur23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
